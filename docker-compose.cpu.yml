# CPU Development Docker Compose
# Only external dependencies: Ollama (CPU) + ROS2
# Run local Python from nimbus-ai/ directory

services:
  # Central ROS2 + RTAB-Map Container
  ros2-central:
    image: introlab3it/rtabmap_ros:humble
    container_name: ros2-central
    ports:
      - 11311:11311  # ROS Master
      - 9090:9090    # ROS Bridge WebSocket
    environment:
      - ROS_DOMAIN_ID=0  
      - DISPLAY=${DISPLAY}
    networks:
      - nimbus-network
    volumes:
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      - ./ros2-config:/ros2_ws/src/nimbus_config
    privileged: true
    devices:
      - /dev:/dev
    command: ["bash", "-c", "source /opt/ros/humble/setup.bash && apt update && apt install -y ros-humble-rosbridge-suite && ros2 run rosbridge_server rosbridge_websocket --ros-args -p port:=9090 & tail -f /dev/null"]
    stdin_open: true
    tty: true

  # Ollama LLM Container (CPU Only)
  ollama:
    image: ollama/ollama:latest
    container_name: nimbus-ollama-cpu
    ports:
      - 11434:11434
    volumes:
      - ollama-cpu:/root/.ollama
    networks:
      - nimbus-network
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_MAX_LOADED_MODELS=1

networks:
  nimbus-network:
    driver: bridge

volumes:
  ollama-cpu:
    external: true